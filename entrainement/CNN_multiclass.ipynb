{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-10T10:15:44.498894Z",
     "end_time": "2023-08-10T10:15:49.179140Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Objectif\n",
    "Notre ambition est de concevoir un modèle basé sur les réseaux de neurones convolutionnels capable d'identifier précisément le type d'attaque présente dans notre dataset. Pour ce faire, nous nous appuierons sur des fichiers Excel déjà prétraités et prêts à l'emploi."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importation des données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Data/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv',\n",
    "                         low_memory=False)\n",
    "data_test = pd.read_csv('Data/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv',\n",
    "                        low_memory=False)\n",
    "# x = dataset.iloc[:, 1:44].values\n",
    "# y = dataset.iloc[:, 44].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T10:15:49.179823Z",
     "end_time": "2023-08-10T10:15:50.086580Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prétraitement des données\n",
    "Cette fonction est conçue pour prétraiter les données en vue d'une utilisation avec des réseaux de neurones convolutionnels (CNN). Elle prend en entrée un tableau data et réalise les étapes suivantes :\n",
    "- Normalisation des features : Les caractéristiques sélectionnées sont converties en float et normalisé pour avoir des valeurs comprises entre 0 et 1. Cette normalisation est essentielle pour s'assurer que toutes les caractéristiques ont le même poids lors de l'entraînement du modèle.\n",
    "\n",
    "- Encodage des Étiquettes : Les étiquettes textuelles de l'ensemble de données sont d'abord transformées en étiquettes numériques à l'aide d'un LabelEncoder. Exemple : 'Normal' devient 0, 'Exploits' devient 1, etc. Ensuite, pour permettre une classification multiclasse, ces étiquettes numériques sont transformées en étiquettes binaires à l'aide d'un LabelBinarizer. Ce qui permet d'obtenir de nouvelles colonnes pour chaque étiquette, avec des valeurs binaires (0 ou 1) indiquant si l'échantillon appartient à cette classe ou non.\n",
    "\n",
    "- Adaptation à l'entrée CNN: Les CNN traitent des images en 3D, avec une hauteur, une largeur et des canaux (comme les couleurs RGB). Nos données sont en 1D, donc nous les transformons pour qu'elles ressemblent à de petites \"images\" 3D. Chaque échantillon devient une \"image\" avec la longueur des caractéristiques comme hauteur, une largeur de 1 et un canal unique. Ainsi, nous pouvons utiliser un CNN sur des données qui ne sont pas vraiment des images.\n",
    "\n",
    "La fonction renvoie finalement deux tableaux : x, qui contient les caractéristiques prétraitées et remodelées, et y, qui contient les étiquettes binarisées. La forme 3D de x est particulièrement adaptée pour être utilisée comme entrée dans un réseau de neurones convolutionnel."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # Initialisation des outils de prétraitement\n",
    "    scaler = MinMaxScaler()  # Transformation des données en valeurs comprises entre 0 et 1\n",
    "    label_encoder = LabelEncoder()  # Transformation des étiquettes textuelles en étiquettes numériques\n",
    "    label_binarizer = LabelBinarizer()  # Transformation des étiquettes multiclasse en étiquettes binaires\n",
    "\n",
    "    # Sélection des caractéristiques spécifiées pour l'ensemble de test\n",
    "    x = data[:, [1, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 32, 33, 34, 35, 36]]\n",
    "\n",
    "    # Conversion des données en flottants et normalisation\n",
    "    x = x.astype(float)\n",
    "    scaler.fit(x)  # Calcul des paramètres de normalisation\n",
    "    x = scaler.transform(x)  # Normalisation des données\n",
    "\n",
    "    # Récupération des étiquettes de l'ensemble de test\n",
    "    label = data[:, 43]  # 43 = attack_cat\n",
    "\n",
    "    # Encodage des étiquettes textuelles en étiquettes numériques\n",
    "    label_encoder.fit(label)\n",
    "    y = label_encoder.transform(label)\n",
    "\n",
    "    # Transformation des étiquettes numériques en étiquettes binaires\n",
    "    label_binarizer.fit(y)\n",
    "    y = label_binarizer.transform(y)\n",
    "\n",
    "    # Remodelage des données pour les adapter à l'entrée 3D attendue par CNN\n",
    "    x_final = []\n",
    "    size = np.size(x, axis=1)\n",
    "    for sample in x:\n",
    "        reshaped_sample = sample.reshape([size, 1, 1])\n",
    "        x_final.append(reshaped_sample)\n",
    "    x = np.array(x_final)\n",
    "\n",
    "    # La fonction renvoie les données prétraitées pour les caractéristiques et les étiquettes\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T10:15:50.075745Z",
     "end_time": "2023-08-10T10:15:50.089684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x_train, y_train = preprocess(data_train.values)\n",
    "x_test, y_test = preprocess(data_test.values)\n",
    "\n",
    "shape = np.size(x_train, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T10:15:50.092104Z",
     "end_time": "2023-08-10T10:15:50.613455Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "nb_classes = y_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T10:15:50.614275Z",
     "end_time": "2023-08-10T10:15:50.616445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "       0  1  2  3  4  5  6  7  8  9\n0      0  0  0  0  0  0  1  0  0  0\n1      0  0  0  0  0  0  1  0  0  0\n2      0  0  0  0  0  0  1  0  0  0\n3      0  0  0  0  0  0  1  0  0  0\n4      0  0  0  0  0  0  1  0  0  0\n...   .. .. .. .. .. .. .. .. .. ..\n82327  0  0  0  0  0  0  1  0  0  0\n82328  0  0  0  0  0  0  1  0  0  0\n82329  0  0  0  0  0  0  1  0  0  0\n82330  0  0  0  0  0  0  1  0  0  0\n82331  0  0  0  0  0  0  1  0  0  0\n\n[82332 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>82327</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82328</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82329</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82330</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82331</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>82332 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train to dataframe\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T10:19:18.276289Z",
     "end_time": "2023-08-10T10:19:18.280863Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Création du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model = Sequential()  # Initialisation du modèle\n",
    "\n",
    "### Bloc 1\n",
    "## Deux couches de convolution avec une fonction d'activation ReLU\n",
    "# 64 filtres de taille 3x1\n",
    "# input_shape = (16 caractéristiques, 1 hauteur, 1 canal)\n",
    "model.add(Conv2D(64, (3, 1), activation='relu', input_shape=(shape, 1, 1)))\n",
    "model.add(Conv2D(64, (3, 1), activation='relu'))\n",
    "\n",
    "## Couche de Pooling\n",
    "# Réduit la complexité du modèle en réduisant la taille des données\n",
    "# 2x1 filtre → réduit de 2 la hauteur et conserve la largeur\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "## Trois couches de convolution\n",
    "# 128 filtres de taille 3x1\n",
    "# padding=\"same\" → assure que la sortie à la même taille que l'entrée\n",
    "# ce qui permet d'éviter la perte d'information\n",
    "model.add(Conv2D(128, (3, 1), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 1), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(128, (3, 1), activation='relu', padding=\"same\"))\n",
    "\n",
    "## Couche de Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "## Trois couches de convolution\n",
    "model.add(Conv2D(256, (3, 1), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(256, (3, 1), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(256, (3, 1), activation='relu', padding=\"same\"))\n",
    "\n",
    "## Couche de Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "# Aplatir les données en un vecteur 1D (actuellement 3D)\n",
    "model.add(Flatten())\n",
    "\n",
    "### Bloc 2\n",
    "## Deux couches entièrement connectées\n",
    "# 100 neurones\n",
    "model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "# Dropout → évite le surapprentissage\n",
    "# 50% des neurones sont ignorés aléatoirement à chaque itération, force le modèle à apprendre de nouvelles représentations\n",
    "model.add(Dropout(0.5))\n",
    "# name='output' → nomme la couche pour pouvoir y accéder plus tard\n",
    "model.add(Dense(20, kernel_initializer='normal', activation='relu', name='output'))\n",
    "\n",
    "# Couche de sortie\n",
    "# 10 neurones → 10 classes\n",
    "# softmax → fonction d'activation pour les problèmes de classification multiclasse\n",
    "model.add(Dense(nb_classes, kernel_initializer='normal', activation='softmax'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T18:22:08.706808Z",
     "end_time": "2023-08-08T18:22:08.758154Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compilation du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647/1647 [==============================] - ETA: 0s - loss: 0.8626 - categorical_accuracy: 0.6953WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647/1647 [==============================] - 17s 10ms/step - loss: 0.8626 - categorical_accuracy: 0.6953 - val_loss: 0.6232 - val_categorical_accuracy: 0.7719\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x29fe30890>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiseur Adam → algorithme de descente de gradient stochastique\n",
    "# metrics=['categorical_accuracy'] → mesure la précision du modèle\n",
    "opt = optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['categorical_accuracy'])\n",
    "\n",
    "# Permet d'arrêter l'entraînement si l'accuracy ne s'améliore plus (3 itérations)\n",
    "stopper = EarlyStopping(monitor='val_binary_accuracy', patience=3, mode='auto')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=50, validation_data=(x_train, y_train), callbacks=[stopper])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T18:22:08.758683Z",
     "end_time": "2023-08-08T18:22:26.164763Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sauvegarde du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T18:22:26.164303Z",
     "end_time": "2023-08-08T18:22:26.203296Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Évaluation du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5480/5480 [==============================] - 10s 2ms/step - loss: 0.8592 - categorical_accuracy: 0.7058\n",
      "Erreur sur les données de test : 0.8592361807823181\n",
      "Précision sur les données de test : 70.58075666427612 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Erreur sur les données de test :\", score[0])\n",
    "print(\"Précision sur les données de test :\", score[1]*100, \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T18:22:26.187283Z",
     "end_time": "2023-08-08T18:22:35.750496Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Source:\n",
    "- https://github.com/CharlesMure/cassiope-NIDS/tree/master"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
