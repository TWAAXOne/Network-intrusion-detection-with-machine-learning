{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-08T12:07:06.500377Z",
     "end_time": "2023-08-08T12:07:06.537069Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importation des données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Data/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_training-set.csv',\n",
    "                         low_memory=False)\n",
    "data_test = pd.read_csv('Data/UNSW-NB15 - CSV Files/a part of training and testing set/UNSW_NB15_testing-set.csv',\n",
    "                        low_memory=False)\n",
    "# x = dataset.iloc[:, 1:44].values\n",
    "# y = dataset.iloc[:, 44].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T12:07:06.506406Z",
     "end_time": "2023-08-08T12:07:07.303791Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prétraitement des données\n",
    "Cette fonction est conçue pour prétraiter les données en vue d'une utilisation avec des réseaux de neurones convolutionnels (CNN). Elle prend en entrée un tableau data et réalise les étapes suivantes :\n",
    "- Normalisation des features : Les caractéristiques sélectionnées sont converties en float et normalisé pour avoir des valeurs comprises entre 0 et 1. Cette normalisation est essentielle pour s'assurer que toutes les caractéristiques ont le même poids lors de l'entraînement du modèle.\n",
    "\n",
    "- Encodage des Étiquettes : Les étiquettes textuelles de l'ensemble de données sont d'abord transformées en étiquettes numériques à l'aide d'un LabelEncoder. Exemple : 'Normal' devient 0, 'Exploits' devient 1, etc. Ensuite, pour permettre une classification multiclasse, ces étiquettes numériques sont transformées en étiquettes binaires à l'aide d'un LabelBinarizer. Ce qui permet d'obtenir de nouvelles colonnes pour chaque étiquette, avec des valeurs binaires (0 ou 1) indiquant si l'échantillon appartient à cette classe ou non.\n",
    "\n",
    "- Adaptation à l'entrée CNN: Les CNN traitent des images en 3D, avec une hauteur, une largeur et des canaux (comme les couleurs RGB). Nos données sont en 1D, donc nous les transformons pour qu'elles ressemblent à de petites \"images\" 3D. Chaque échantillon devient une \"image\" avec la longueur des caractéristiques comme hauteur, une largeur de 1 et un canal unique. Ainsi, nous pouvons utiliser un CNN sur des données qui ne sont pas vraiment des images.\n",
    "\n",
    "La fonction renvoie finalement deux tableaux : x, qui contient les caractéristiques prétraitées et remodelées, et y, qui contient les étiquettes binarisées. La forme 3D de x est particulièrement adaptée pour être utilisée comme entrée dans un réseau de neurones convolutionnel."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # Initialisation des outils de prétraitement\n",
    "    scaler = MinMaxScaler()  # Transformation des données en valeurs comprises entre 0 et 1\n",
    "    label_encoder = LabelEncoder()  # Transformation des étiquettes textuelles en étiquettes numériques\n",
    "    label_binarizer = LabelBinarizer()  # Transformation des étiquettes multiclasse en étiquettes binaires\n",
    "\n",
    "    # Sélection des caractéristiques spécifiées pour l'ensemble de test\n",
    "    x = data[:, [1, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 32, 33, 34, 35, 36]]\n",
    "\n",
    "    # Conversion des données en flottants et normalisation\n",
    "    x = x.astype(float)\n",
    "    scaler.fit(x)  # Calcul des paramètres de normalisation\n",
    "    x = scaler.transform(x)  # Normalisation des données\n",
    "\n",
    "    # Récupération des étiquettes de l'ensemble de test\n",
    "    label = data[:, 43]  # 43 = attack_cat\n",
    "\n",
    "    # Encodage des étiquettes textuelles en étiquettes numériques\n",
    "    label_encoder.fit(label)\n",
    "    y = label_encoder.transform(label)\n",
    "\n",
    "    # Transformation des étiquettes numériques en étiquettes binaires\n",
    "    label_binarizer.fit(y)\n",
    "    y = label_binarizer.transform(y)\n",
    "\n",
    "    # Remodelage des données pour les adapter à l'entrée 3D attendue par CNN\n",
    "    x_final = []\n",
    "    size = np.size(x, axis=1)\n",
    "    for sample in x:\n",
    "        reshaped_sample = sample.reshape([size, 1, 1])\n",
    "        x_final.append(reshaped_sample)\n",
    "    x = np.array(x_final)\n",
    "\n",
    "    # La fonction renvoie les données prétraitées pour les caractéristiques et les étiquettes\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T12:07:07.305933Z",
     "end_time": "2023-08-08T12:07:07.308148Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "x_train, y_train = preprocess(data_train.values)\n",
    "x_test, y_test = preprocess(data_test.values)\n",
    "\n",
    "shape = np.size(x_train, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T12:07:07.308877Z",
     "end_time": "2023-08-08T12:07:07.820184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "nb_classes = y_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T12:07:07.826053Z",
     "end_time": "2023-08-08T12:07:07.826707Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "model = Sequential()  # Initialisation du modèle\n",
    "\n",
    "### Bloc 1\n",
    "## Deux couches de convolution avec une fonction d'activation ReLU\n",
    "# 64 filtres de taille 3x1\n",
    "# input_shape = (16 caractéristiques, 1 hauteur, 1 canal)\n",
    "model.add(Conv2D(64, (3, 1), activation='relu', input_shape=(shape, 1, 1)))\n",
    "model.add(Conv2D(64, (3, 1), activation='relu'))\n",
    "\n",
    "## Couche de Pooling\n",
    "# Réduit la complexité du modèle en réduisant la taille des données\n",
    "# 2x1 filtre → réduit de 2 la hauteur et conserve la largeur\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "## Trois couches de convolution\n",
    "# 128 filtres de taille 3x1\n",
    "# padding=\"same\" → assure que la sortie à la même taille que l'entrée\n",
    "# ce qui permet d'éviter la perte d'information\n",
    "model.add(Conv2D(128, (3, 1), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 1), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(128, (3, 1), activation='relu', padding=\"same\"))\n",
    "\n",
    "## Couche de Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "## Trois couches de convolution\n",
    "model.add(Conv2D(256, (3, 1), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(256, (3, 1), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(256, (3, 1), activation='relu', padding=\"same\"))\n",
    "\n",
    "## Couche de Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "# Aplatir les données en un vecteur 1D (actuellement 3D)\n",
    "model.add(Flatten())\n",
    "\n",
    "### Bloc 2\n",
    "## Deux couches entièrement connectées\n",
    "# 100 neurones\n",
    "model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "# Dropout → évite le surapprentissage\n",
    "# 50% des neurones sont ignorés aléatoirement à chaque itération, force le modèle à apprendre de nouvelles représentations\n",
    "model.add(Dropout(0.5))\n",
    "# name='output' → nomme la couche pour pouvoir y accéder plus tard\n",
    "model.add(Dense(20, kernel_initializer='normal', activation='relu', name='output'))\n",
    "\n",
    "# Couche de sortie\n",
    "# 10 neurones → 10 classes\n",
    "# softmax → fonction d'activation pour les problèmes de classification multiclasse\n",
    "model.add(Dense(nb_classes, kernel_initializer='normal', activation='softmax'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T12:07:07.830209Z",
     "end_time": "2023-08-08T12:07:07.887011Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compilation du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1647 [============================>.] - ETA: 0s - loss: 0.9199 - categorical_accuracy: 0.6657WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: loss,categorical_accuracy,val_loss,val_categorical_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647/1647 [==============================] - 17s 10ms/step - loss: 0.9195 - categorical_accuracy: 0.6659 - val_loss: 0.6701 - val_categorical_accuracy: 0.7660\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x15bf5b9d0>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiseur Adam → algorithme de descente de gradient stochastique\n",
    "# metrics=['categorical_accuracy'] → mesure la précision du modèle\n",
    "opt = optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['categorical_accuracy'])\n",
    "\n",
    "# Permet d'arrêter l'entraînement si l'accuracy ne s'améliore plus (3 itérations)\n",
    "stopper = EarlyStopping(monitor='val_binary_accuracy', patience=3, mode='auto')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=50, validation_data=(x_train, y_train), callbacks=[stopper])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T12:07:07.887757Z",
     "end_time": "2023-08-08T12:07:24.753427Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sauvegarde du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T12:07:24.735166Z",
     "end_time": "2023-08-08T12:07:24.755343Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Évaluation du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5480/5480 [==============================] - 9s 2ms/step - loss: 0.8476 - categorical_accuracy: 0.7035\n",
      "Erreur sur les données de test : 0.8475897312164307\n",
      "Précision sur les données de test : 70.35148739814758 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Erreur sur les données de test :\", score[0])\n",
    "print(\"Précision sur les données de test :\", score[1]*100, \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-08T12:14:36.402565Z",
     "end_time": "2023-08-08T12:14:45.960172Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création du modèle (Tentative 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Couche de convolution initiale\n",
    "# 32 filtres de taille 3x3\n",
    "# 'relu' est utilisé comme fonction d'activation pour ajouter de la non-linéarité\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "\n",
    "# Couche de pooling pour réduire la dimensionnalité tout en conservant les caractéristiques\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Seconde couche de convolution\n",
    "# Utilise également 32 filtres de taille 3x3\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Flattening: transforme le format 2D de la carte des caractéristiques en un vecteur 1D\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Première couche entièrement connectée (Dense)\n",
    "# 128 neurones, fonction d'activation 'relu'\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Dropout pour éviter le surapprentissage. Désactive 50% des neurones de manière aléatoire pendant chaque itération d'entraînement.\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "# Couche de sortie\n",
    "# Une seule unité pour une classification binaire avec fonction d'activation sigmoïde pour obtenir une probabilité\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilation du modèle\n",
    "# Utilisation de l'optimiseur 'adam' pour la descente de gradient\n",
    "# Utilisation de la fonction de perte 'binary_crossentropy' pour la classification binaire\n",
    "# Utilisation de la métrique 'accuracy' pour évaluer les performances du modèle\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "# Supposons que `train_data` et `train_labels` soient vos données et labels d'entraînement\n",
    "# et que `val_data` et `val_labels` soient vos données et labels de validation.\n",
    "# epochs représente le nombre de fois où l'ensemble des données d'entraînement est utilisé pour l'apprentissage\n",
    "# batch_size représente le nombre d'échantillons qui seront propagés à travers le réseau à la fois.\n",
    "classifier.fit(x, y, epochs=10, batch_size=32, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
